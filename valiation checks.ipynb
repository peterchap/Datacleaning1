{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Country Code: 44 National Number: 7768438500\n"
    }
   ],
   "source": [
    "import phonenumbers\n",
    "\n",
    "x= phonenumbers.parse(\"+447768438500\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'O2'"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "from phonenumbers import carrier\n",
    "ro_number = phonenumbers.parse (\"7922625595\", 'GB')\n",
    "carrier.name_for_number(ro_number, \"e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'Vodafone'"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "from phonenumbers import carrier\n",
    "ro_number = phonenumbers.parse (\"7768000000\", 'GB')\n",
    "carrier.name_for_number(ro_number, \"e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import PostCodeClient\n",
    "client = PostCodeClient()\n",
    "client.getLookupPostCode('WN7 3AJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import PostCodeClient\n",
    "client = PostCodeClient()\n",
    "client.getLookupPostCode('rg40 2dh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import postcodes_io_api\n",
    "api  = postcodes_io_api.Api(debug_http=True)\n",
    "api.get_postcode('WF16 0DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import postcodes_io_api\n",
    "api  = postcodes_io_api.Api(debug_http=True)\n",
    "data = api.is_postcode_valid('rg402dh')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GOOD TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from goodtables import validate\n",
    "directory = 'E:/MDEG/JNB/Mdeg UK Wininaclick/'\n",
    "file = 'UK File 20 - 20.05.2020.csv'\n",
    "report = validate(directory + file, checks=['structure'], row_limit= 3000000)\n",
    "print(report['tables'][0]['headers'])\n",
    "data = report['tables'][0]['errors']\n",
    "#for x in data:\n",
    "#    if x['code'] != 'duplicate-row':\n",
    "#        print(x['message'])\n",
    "print('processing complete')\n",
    "#print(report['tables'][0]['errors'][0]['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re \n",
    "  \n",
    "# Make a regular expression \n",
    "# for validating an Ip-address \n",
    "regex = '''^(25[0-5]|2[0-4][0-9]|[0-1]?[0-9][0-9]?)\\.( \n",
    "            25[0-5]|2[0-4][0-9]|[0-1]?[0-9][0-9]?)\\.( \n",
    "            25[0-5]|2[0-4][0-9]|[0-1]?[0-9][0-9]?)\\.( \n",
    "            25[0-5]|2[0-4][0-9]|[0-1]?[0-9][0-9]?)$'''\n",
    "      \n",
    "# Define a function for \n",
    "# validate an Ip addess \n",
    "def check(Ip):  \n",
    "  \n",
    "    # pass the regular expression \n",
    "    # and the string in search() method \n",
    "    if(re.search(regex, Ip)):  \n",
    "        print(\"Valid Ip address\")  \n",
    "          \n",
    "    else:  \n",
    "        print(\"Invalid Ip address\")  \n",
    "\n",
    "check('86158211243')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"peter.test\")\n",
    "location = geolocator.reverse(\"53.705494, -1.663196\")\n",
    "a = location.address\n",
    "print(a)\n",
    "#print((location.latitude, location.longitude))\n",
    "#print(location.raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a= 'http://www.ordnancesurvey.co.uk/xml/codelists/localtype.xml#village'\n",
    "pos = a.find('#')\n",
    "b = a[pos+1:]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Northfield Grove Northfield Grove\n"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "x = '3/1 Northfield Grove Northfield Grove'\n",
    "\n",
    "pat = re.compile(r'[^a-zA-Z ]+')\n",
    "y=re.sub(pat, '', x)\n",
    "\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "#nltk.download('punkt')\n",
    "\n",
    "x = '3/1 Northfield grove Northfield Grove'\n",
    "\n",
    "pat = re.compile(r'[^a-zA-Z ]+')\n",
    "y=string.capwords(re.sub(pat, '', x))\n",
    "\n",
    "nltk_tokens = nltk.word_tokenize(y)\n",
    "\n",
    "ordered_tokens = set()\n",
    "result = []\n",
    "for word in nltk_tokens:\n",
    "    if word not in ordered_tokens:\n",
    "        ordered_tokens.add(word)\n",
    "        result.append(word)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Northfield Grove\n"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "x = '3/1 Northfield grove Northfield Grove'\n",
    "\n",
    "pat = re.compile(r'[^a-zA-Z ]+')\n",
    "y=string.capwords(re.sub(pat, '', x))\n",
    "\n",
    "result = ' '.join(dict.fromkeys(y.split()))\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\n"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "NON_ALPHA_RE = re.compile('[^A-Z0-9]+')\n",
    "POSTCODE_RE = re.compile('^[A-Z]{1,2}[0-9]{1,2}[A-Z]? [0-9][A-Z]{2}$')\n",
    "\n",
    "def normalise_postcode(postcode):\n",
    "    \"\"\"Return a normalised postcode if valid, or None if not.\"\"\"\n",
    "\n",
    "    postcode = NON_ALPHA_RE.sub('', postcode.upper())\n",
    "    postcode = postcode[:-3] + ' ' + postcode[-3:]\n",
    "    if POSTCODE_RE.match(postcode):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "print(normalise_postcode('rg40 2dh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\"THE | big,- Pharma\n"
    }
   ],
   "source": [
    "from cleanco import prepare_terms, basename\n",
    "\n",
    "name = '\"THE |  big,- Pharma: LLC'\n",
    "terms = prepare_terms()\n",
    "result = basename(name, terms, prefix=False, middle=False, suffix=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the | big,- pharma\nthe  big pharma\n['the', 'big', 'pharma']\n"
    }
   ],
   "source": [
    "import nltk\n",
    "from cleanco import prepare_terms, basename\n",
    "\n",
    "name = \"THE |  big,- Pharma: LLC\"\n",
    "name = name.lower()\n",
    "terms = prepare_terms()\n",
    "result = basename(name, terms, prefix=False, middle=False, suffix=True)\n",
    "print(result)\n",
    "newname = result.translate(str.maketrans('', '', string.punctuation))\n",
    "print(newname)\n",
    "\n",
    "#name = regex.sub(ur'[[:punct:]]+', \"\", name)\n",
    "\n",
    "tokens = nltk.word_tokenize(newname)  # ['THE', 'big', 'Pharma']\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "cannot import name 'Phonetics' from 'phonetics' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\phonetics\\__init__.py)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-7f094c0a13d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mphonetics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPhonetics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlevenshtein\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msize_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Phonetics' from 'phonetics' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\phonetics\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from phonetics import Phonetics\n",
    "import numpy as np\n",
    "\n",
    "def levenshtein(seq1, seq2):  \n",
    "    size_x = len(seq1) + 1\n",
    "    size_y = len(seq2) + 1\n",
    "    matrix = np.zeros ((size_x, size_y))\n",
    "    for x in xrange(size_x):\n",
    "        matrix [x, 0] = x\n",
    "    for y in xrange(size_y):\n",
    "        matrix [0, y] = y\n",
    "\n",
    "    for x in xrange(1, size_x):\n",
    "        for y in xrange(1, size_y):\n",
    "            if seq1[x-1] == seq2[y-1]:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1, y] + 1,\n",
    "                    matrix[x-1, y-1],\n",
    "                    matrix[x, y-1] + 1\n",
    "                )\n",
    "            else:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1,y] + 1,\n",
    "                    matrix[x-1,y-1] + 1,\n",
    "                    matrix[x,y-1] + 1\n",
    "                )\n",
    "    return (matrix[size_x - 1, size_y - 1])\n",
    "\n",
    "# -- initialize phonetics object\n",
    "\n",
    "word1 = Phonetics(\" 1 to 1\")\n",
    "word2 = Phonetics(\"1-2-1\")\n",
    "print (\"Comparing %s with %s\" % (word1.getText(), word2.getText()))\n",
    "\n",
    "# -- phonetic code\n",
    "codeList1 = word1.phoneticCode()\n",
    "codeList2 = word2.phoneticCode()\n",
    "\n",
    "# -- weight\n",
    "weight = {\n",
    "    \"soundex\": 0.2,\n",
    "    \"caverphone\": 0.2,\n",
    "    \"metaphone\": 0.5,\n",
    "    \"nysiis\": 0.1\n",
    "}\n",
    "\n",
    "# -- algorithms\n",
    "algorithms = [\"soundex\", \"caverphone\", \"metaphone\", \"nysiis\"]\n",
    "\n",
    "# -- total\n",
    "total = 0.0\n",
    "for entry in algorithms:\n",
    "    code1 = codeList1[entry]\n",
    "    code2 = codeList2[entry]\n",
    "    lev = levenshtein (code1, code2)\n",
    "    currentWeight = weight[entry]\n",
    "    print (\"comparing %s with %s for %s (%0.2f: weight %0.2f)\" % (code1, code2, entry, lev, currentWeight))\n",
    "    subtotal = lev * currentWeight\n",
    "    total += subtotal\n",
    "\n",
    "print (\"total: %0.2f\" % total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "36"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "fuzz.ratio(\"1 to 1\", \"1-2-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1 to 1     [b'T', None]\n1-2-1      [None, None]\none two one [b'ANTN', None]\nJohnathan  [b'JN0N', b'ANTN']\nJonathan   [b'JN0N', b'ANTN']\nJohn       [b'JN', b'AN']\nTeresa     [b'TRS', None]\nTheresa    [b'0RS', b'TRS']\nSmith      [b'SM0', b'XMT']\nSmyth      [b'SM0', b'XMT']\nJessica    [b'JSK', b'ASK']\nJoshua     [b'JX', b'AX']\n"
    }
   ],
   "source": [
    "import fuzzy\n",
    "\n",
    "names = [ '1 to 1', '1-2-1', 'one two one',\n",
    "          'Johnathan', 'Jonathan', 'John',\n",
    "          'Teresa', 'Theresa',\n",
    "          'Smith', 'Smyth',\n",
    "          'Jessica',\n",
    "          'Joshua',\n",
    "          ]\n",
    "\n",
    "dmetaphone = fuzzy.DMetaphone(4)\n",
    "soundex = fuzzy.Soundex(4)\n",
    "dmeta = fuzzy.DMetaphone()\n",
    "\n",
    "for n in names:\n",
    "    print('%-10s' % n, dmeta(n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "95\n"
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "Str1 = \"Apple Inc.\"\n",
    "Str2 = \"apple Inc\"\n",
    "Ratio = fuzz.ratio(Str1.lower(),Str2.lower())\n",
    "print(Ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('Apple Inc.', 100), ('apple incorporated', 90), ('apple park', 67), ('iphone', 30)]\n('Apple Inc.', 100)\n"
    }
   ],
   "source": [
    "from fuzzywuzzy import process\n",
    "str2Match = \"apple inc\"\n",
    "strOptions = [\"Apple Inc.\",\"apple park\",\"apple incorporated\",\"iphone\"]\n",
    "Ratios = process.extract(str2Match,strOptions)\n",
    "print(Ratios)\n",
    "\n",
    "highest = process.extractOne(str2Match,strOptions)\n",
    "print(highest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(0.9090909090909091, 'ESB Connect')]"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "from cfuzzyset import cFuzzySet as FuzzySet\n",
    "\n",
    "a = FuzzySet()\n",
    "a.add(\"ESB Connect\")\n",
    "a.get(\"esbconnect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "s = '12-34'\n",
    "isinstance(s, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}